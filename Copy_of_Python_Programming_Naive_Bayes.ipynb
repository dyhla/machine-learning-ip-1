{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Python Programming: Naive Bayes",
      "provenance": [],
      "collapsed_sections": [
        "L2AZSQI69LWk",
        "EcX1UM0w22nz",
        "8dDIovl6-Bdz",
        "Oxk9l9YaWgYw",
        "hCf-nbGD24qA",
        "3zlzFxHy2-ky",
        "JwUCSxpP3AHd"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dyhla/machine-learning-ip-1/blob/main/Copy_of_Python_Programming_Naive_Bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tj0s0p4DeymK"
      },
      "source": [
        "<font color=\"green\">*To start working on this notebook, or any other notebook that we will use in the Moringa Data Science Course, we will need to save our own copy of it. We can do this by clicking File > Save a Copy in Drive. We will then be able to make edits to our own copy of this notebook.*</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSgQHdZS21iD"
      },
      "source": [
        "# Python Programming: Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2AZSQI69LWk"
      },
      "source": [
        "## Example 1: Gaussian Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mw9OAPal9LCI"
      },
      "source": [
        "# Example 1\n",
        "# ---\n",
        "# This type of classifier makes the assumption of normal distribution \n",
        "# thus can be best used in cases when all our features are continuous.\n",
        "# ---\n",
        "# Question: Predict the species of flower using 4 different features.\n",
        "# ---\n",
        "# \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27ozeIT2BoT4"
      },
      "source": [
        "# Load libraries and datasets to be used in this example\n",
        "#\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsdY4zOdB2ky"
      },
      "source": [
        "# Loading our data from python datasets\n",
        "# \n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbScEK1FGA0p"
      },
      "source": [
        "# Splitting our data into a training set and a test set\n",
        "# \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=6) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PV2q7CeTB6P7"
      },
      "source": [
        "# Training our model\n",
        "# \n",
        "clf = GaussianNB()  \n",
        "model = clf.fit(X_train, y_train) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfovw-T6CJ0U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3457b4e-de97-4c8a-f5d7-8e3ccb2d3267"
      },
      "source": [
        "# Predicting our test predictors\n",
        "predicted = model.predict(X_test)\n",
        "print(np.mean(predicted == y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtGeQcvkB-s6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96f7e062-6081-434f-96ca-2b2eac2bc680"
      },
      "source": [
        "# Predicting a new observation\n",
        "new_observation = [[ 10,  3,  4,  0.4]]\n",
        "\n",
        "new_prediction = model.predict(new_observation)\n",
        "new_prediction"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcX1UM0w22nz"
      },
      "source": [
        "## Example 2: Multinomial Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bczlBDgf2wd6"
      },
      "source": [
        "# Example 2\n",
        "# ---\n",
        "# While working with the multinomial naive bayes classifier, the features are assumed to be multinomially distributed. \n",
        "# This would mean that this type of classifier is commonly used when we have discrete data (e.g. movie ratings 1 and 5).\n",
        "# Let us see how this works.\n",
        "# ----\n",
        "# Question: Build a model to predict whether an sms message is spam or not.\n",
        "# ---\n",
        "# Dataset url = http://bit.ly/SpamCollectionDataset\n",
        "# ---\n",
        "# \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAsqH_uz3h_p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c8d7194-1681-4b1b-c799-df056368fbce"
      },
      "source": [
        "# Importing our libraries \n",
        "\n",
        "# Importing pandas\n",
        "import pandas as pd\n",
        "\n",
        "# Importing numpy\n",
        "import numpy as np\n",
        "\n",
        "# We will also download and import nlkt which is a tokenizer. \n",
        "# This library will help us break (messages) into individual linguistic units i.e. words.\n",
        "#\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTtlH2q34L4K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "94218de0-94dd-497d-e391-9c154ab4f688"
      },
      "source": [
        "# Loading and previewing our dataset\n",
        "# \n",
        "df = pd.read_csv('http://bit.ly/SpamCollectionDataset', sep='\\t',  header = None, names = ['label', 'message'])\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  label                                            message\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-279e8c6d-8191-4967-be2a-3142ba9c96fe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-279e8c6d-8191-4967-be2a-3142ba9c96fe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-279e8c6d-8191-4967-be2a-3142ba9c96fe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-279e8c6d-8191-4967-be2a-3142ba9c96fe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkCF6JuX4oQM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a45b74f-a663-4193-c1a6-fb55b5afae5c"
      },
      "source": [
        "# Pre-processing\n",
        "# We will first emoving useless variance for our task at hand \n",
        "# \n",
        "\n",
        "# Converting the labels from strings to binary values for our classifier\n",
        "# \n",
        "df['label'] = df.label.map({'ham': 0, 'spam': 1})\n",
        "\n",
        "# Converting all characters in the message to lower case\n",
        "# \n",
        "df['message'] = df.message.map(lambda x: x.lower())\n",
        "\n",
        "# Removing any punctuation\n",
        "# \n",
        "df['message'] = df.message.str.replace('[^\\w\\s]', '')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ftbUUxi5UmL"
      },
      "source": [
        "# Pre-processing \n",
        "# Tokenizing the messages into into single words using nltk. \n",
        "\n",
        "# Applying the tokenization\n",
        "# \n",
        "df['message'] = df['message'].apply(nltk.word_tokenize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcxdFpHp5xae"
      },
      "source": [
        "# Fifth, we will perform some word stemming. \n",
        "# The idea of stemming is to normalize our text for all variations of words carry the same meaning, \n",
        "# regardless of the tense. One of the most popular stemming algorithms is the Porter Stemmer:\n",
        "# \n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        " \n",
        "df['message'] = df['message'].apply(lambda x: [stemmer.stem(y) for y in x])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ezXwg2e53v6"
      },
      "source": [
        "# Finally, we will transform the data into occurrences, \n",
        "# which will be the features that we will feed into our model\n",
        "# \n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# This converts the list of words into space-separated strings\n",
        "df['message'] = df['message'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "count_vect = CountVectorizer()\n",
        "counts = count_vect.fit_transform(df['message'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UysRCO4Y6MVI"
      },
      "source": [
        "# We could leave it as the simple word-count per message, but it is better to use Term Frequency Inverse Document Frequency, more known as tf-idf\n",
        "# \n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "transformer = TfidfTransformer().fit(counts)\n",
        "\n",
        "counts = transformer.transform(counts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Knhu0766PtJ"
      },
      "source": [
        "# Training the Model\n",
        "# Now that we have performed feature extraction from our data, it is time to build our model. \n",
        "# We will start by splitting our data into training and test sets\n",
        "# \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(counts, df['label'], test_size=0.1, random_state=69)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjd6-wy16cmg"
      },
      "source": [
        "# Fitting our model \n",
        "# Then, all that we have to do is initialize the Naive Bayes Classifier and fit the data. \n",
        "# For text classification problems, the Multinomial Naive Bayes Classifier is well-suited\n",
        "# \n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "model = MultinomialNB().fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsxzsJuE6mBf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d9c8898-9c15-4c30-adfd-084f8b70106b"
      },
      "source": [
        "# Evaluating the Model\n",
        "# Once we have put together our classifier, we can evaluate its performance in the testing set\n",
        "# \n",
        "predicted = model.predict(X_test)\n",
        "print(np.mean(predicted == y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9480286738351255\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dDIovl6-Bdz"
      },
      "source": [
        "## Example 3: Bernoulli Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bFEsnHL-MAc"
      },
      "source": [
        "# Example 3\n",
        "# ---\n",
        "# Question: It is rare to get a scenario where you have to use the Bernoulli Naive Bayes Classifier. \n",
        "# However, such a case would assume that all our features are binary, \n",
        "# that is they take only two values (e.g. a nominal categorical feature that has been one-hot encoded).\n",
        "# In the following example we will generate a dataset to demonstrate the use of this Classifier.\n",
        "# ---\n",
        "# \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IiBTveYHdub"
      },
      "source": [
        "# Importing our libraries\n",
        "# \n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import BernoulliNB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QI14CBvKHk9h"
      },
      "source": [
        "# Creating binary features and target data\n",
        "# \n",
        "# Creating three binary features\n",
        "X = np.random.randint(2, size=(100, 3))\n",
        "\n",
        "# Creating a binary target vector\n",
        "y = np.random.randint(2, size=(100, 1)).ravel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDg6XbQ7HzpW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08a5b85f-ed5f-4dc1-b12d-8a6a67c9b1ee"
      },
      "source": [
        "# Viewing first ten observations\n",
        "# \n",
        "X[0:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0],\n",
              "       [0, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [1, 1, 0],\n",
              "       [1, 1, 1],\n",
              "       [1, 0, 1],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 1],\n",
              "       [1, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3D_lyUeH4VB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37aa8e9b-527a-46f6-998c-afa8b242aa67"
      },
      "source": [
        "# Training our Bernoulli Naive Bayes Classifier\n",
        "# \n",
        "# Creating oour Bernoulli Naive Bayes object with prior probabilities of each class\n",
        "clf = BernoulliNB()\n",
        "\n",
        "# Train model\n",
        "model = clf.fit(X, y)\n",
        "\n",
        "# model score\n",
        "model.score(X, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.54"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oxk9l9YaWgYw"
      },
      "source": [
        "## <font color=\"green\">Challenge 1</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9VOjyqrWpgj"
      },
      "source": [
        "# Challenge 1\n",
        "# ---\n",
        "# Question: Build a model to determine whether a mushroom is edible.\n",
        "# ---\n",
        "# Dataset url = http://bit.ly/MushroomDataset\n",
        "# \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCf-nbGD24qA"
      },
      "source": [
        "## <font color=\"green\">Challenge 2</font> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfhQpHhe286F"
      },
      "source": [
        "# Challenge 2\n",
        "# ---\n",
        "# Question: Given the following two datasets, build a model to determine whether a passenger survived or not.\n",
        "# ---\n",
        "# Train Dataset url = http://bit.ly/TitanicDatasetTrain\n",
        "# Test Dataset url = http://bit.ly/TitanicDatasetTest\n",
        "# ---\n",
        "# \n",
        "OUR CODE GOES HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zlzFxHy2-ky"
      },
      "source": [
        "## <font color=\"green\">Challenge 3</font> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7ExY54F2_m2"
      },
      "source": [
        "# Challenge 3\n",
        "# ---\n",
        "# Question: Build a model to classify a type of glass given the following dataset.\n",
        "# ---\n",
        "# Dataset url = http://bit.ly/GlassDatasetB\n",
        "# Dataset info:\n",
        "# Type of glass: (class) \n",
        "# -) 1 window glass (from vehicle or building) \n",
        "# -) 2 not window glass (containers, tableware, or headlamps)\n",
        "# ---\n",
        "# \n",
        "OUR CODE GOES HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwUCSxpP3AHd"
      },
      "source": [
        "## <font color=\"green\">Challenge 4</font> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Me_kp5ka3BTh"
      },
      "source": [
        "# Challenge 4\n",
        "# ---\n",
        "# Question: Build a classifier to help determine whether future patients do or do not have heart disease.\n",
        "# ---\n",
        "# Dataset url = http://bit.ly/HeartDatasetNB\n",
        "# \n",
        "OUR CODE GOES HERE"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}